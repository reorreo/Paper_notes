# ITE-MTA


## Title List

1. [Twin Contrastive Learning With Noisy Labels (CVPR2023):TCL]
2. [Longremix: Robust learning with high confidence samples in a noisy label environment (2023)):LongReMix]
3. [A Simple Framework for Contrastive Learning of Visual Representations (PMLR2023):SimCLR]
4. [Momentum Contrast for Unsupervised Visual Representation Learning(CVPR2020):MoCo]
5. [Exploring Simple Siamese Representation Learning(CVPR2021):SimSiam]
6. [Representation Learning with Contrastive Predictive Coding(2018)]
7. [Bootstrap your own latent-a new approach to self-supervised learning(2020):BYOL]
8. [Learning From Noisy Data With Robust Representation Learning(ICCV2021):RRL]
9. [Multi-Objective Interpolation Training for Robustness To Label Noise(CVPR2021):MOIT]
10. [Dividemix: Learning with noisy labels as semi-supervised learning(2020):DivideMix]
11. [mixup: Beyond empirical risk minimization(2017):MixUp]
12. [Probabilistic End-To-End Noise Correction for Learning With Noisy Labels(CVPR2019)]
13. [Unsupervised Label Noise Modeling and Loss Correction(PMLR2019)]
14. [Early-learning regularization prevents memorization of noisy labels(NIPS2020):ELR]
15. [Selective-Supervised Contrastive Learning With Noisy Labels(CVPR2022):Sel-CL]
16. [On Learning Contrastive Representations for Learning With Noisy Labels(CVPR2022):CTRR]
17. [Probabilistic End-To-End Noise Correction for Learning With Noisy Labels(CVPR2019)]
18. [Peer Loss Functions: Learning from Noisy Labels without Knowing Noise Rates(PMLR2020)]
19. [Robust Training under Label Noise by Over-parameterization(PMLR2022)]
20. [A Closer Look at Memorization in Deep Networks(PMLR2017)]
21. [Augmentation Strategies for Learning With Noisy Labels(CVPR2021)]
22. [Understanding deep learning (still) requires rethinking generalization(2021)]
23. [Making Deep Neural Networks Robust to Label Noise: A Loss Correction Approach(2017)]
24. [Learning From Noisy Labels By Regularized Estimation Of Annotator Confusion(2019)]
25. [Are Anchor Points Really Indispensable in Label-Noise Learning?(2019)]
26. [The Multidimensional Wisdom of Crowds(NIPS2010)]
27. [NEIL: Extracting Visual Knowledge from Web Data(ICCV2013)]
28. [Visual Recognition by Learning From Web Data: A Weakly Supervised Domain Generalization Approach(CVPR2015)]
29. [Learning From Massive Noisy Labeled Data for Image Classification(CVPR2015)]
30. [{SELFIE}: Refurbishing Unclean Samples for Robust Deep Learning(PMLR2019)]
31. [WebVision Database: Visual Learning and Understanding from Web Data(CoRR2017)]
32. [Learning with Symmetric Label Noise: The Importance of Being Unhinged(NeurIPS2015)]
33. [Learning multiple layers of features from tiny images(2009cifar)]
34. [Imagenet: A large-scale hierarchical image database(2009ImageNer)]
35. [Visualizing data using t-SNE(2008t-SNE)]
---


### Twin Contrastive Learning With Noisy Labels (CVPR2023):TCL
[[Paper]](https://openaccess.thecvf.com/content/CVPR2023/papers/Huang_Twin_Contrastive_Learning_With_Noisy_Labels_CVPR_2023_paper.pdf)
[[Code]](https://github.com/Hzzone/TCL)
[[bibtex]](https://openaccess.thecvf.com/content/CVPR2023/html/Huang_Twin_Contrastive_Learning_With_Noisy_Labels_CVPR_2023_paper.html)
<details><summary>summary</summary><div>

</div></details> 

### Longremix: Robust learning with high confidence samples in a noisy label environment (2023):LongReMix
[[Paper]](https://www.sciencedirect.com/science/article/pii/S0031320322004939/pdfft?md5=21004c446dccd13a5cd59f6901a41607&pid=1-s2.0-S0031320322004939-main.pdf)
[[Code]](https://github.com/filipe-research/LongReMix)
[[bibtex]](https://www.sciencedirect.com/science/article/pii/S0031320322004939)
<details><summary>summary</summary><div>

</div></details> 

##  対照学習
### A Simple Framework for Contrastive Learning of Visual Representations (PMLR2023):SimCLR
[[Paper]](http://proceedings.mlr.press/v119/chen20j/chen20j.pdf)
[[Code]](https://github.com/google-research/simclr)
[[bibtex]](https://proceedings.mlr.press/v119/chen20j.html)
<details><summary>summary</summary><div>
  
</div></details> 
- Keywords : `Contrastive Learning`


### Momentum Contrast for Unsupervised Visual Representation Learning(CVPR2020):MoCo
[[Paper]](https://openaccess.thecvf.com/content_CVPR_2020/papers/He_Momentum_Contrast_for_Unsupervised_Visual_Representation_Learning_CVPR_2020_paper.pdf)
[]([[Code]])
[[bibtex]](https://openaccess.thecvf.com/content_CVPR_2020/html/He_Momentum_Contrast_for_Unsupervised_Visual_Representation_Learning_CVPR_2020_paper.htmll)
<details><summary>summary</summary><div>
  
</div></details> 
- Keywords : `Contrastive Learning`

### Exploring Simple Siamese Representation Learning(CVPR2021):SimSiam
[[Paper]](https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Exploring_Simple_Siamese_Representation_Learning_CVPR_2021_paper.pdf)
[[Code]](https://github.com/facebookresearch/simsiam)
[[bibtex]](https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Exploring_Simple_Siamese_Representation_Learning_CVPR_2021_paper.html)
<details><summary>summary</summary><div>
  
</div></details> 
- Keywords : `Contrastive Learning`

### Representation Learning with Contrastive Predictive Coding(2018)
[[Paper]](https://arxiv.org/pdf/1807.03748)
[[bibtex]](https://arxiv.org/abs/1807.03748)
<details><summary>summary</summary><div>
  TCL内でInfoNCEの説明に使われている．
</div></details> 
- Keywords : `Contrastive Learning`


### Bootstrap your own latent-a new approach to self-supervised learning(2020):BYOL
[[Paper]](https://proceedings.neurips.cc/paper_files/paper/2020/file/f3ada80d5c4ee70142b17b8192b2958e-Paper.pdf)
<details><summary>summary</summary><div>

</div></details> 
- Keywords : `Contrastive Learning`

### Learning From Noisy Data With Robust Representation Learning(ICCV2021):RRL
[[Paper]](https://openaccess.thecvf.com/content/ICCV2021/papers/Li_Learning_From_Noisy_Data_With_Robust_Representation_Learning_ICCV_2021_paper.pdf)
[[bibtex]](https://openaccess.thecvf.com/content/ICCV2021/html/Li_Learning_From_Noisy_Data_With_Robust_Representation_Learning_ICCV_2021_paper.html)
<details><summary>summary</summary><div>
InfoNCEの損失をMixUpしている?．今後の研究でしたいことと似ているため読む必要がある．
対照学習を用いたノイジーラベルに対する手法の例として挙げられていた．
</div></details> 
- Keywords : `Contrastive Learning` 'MixUp'

### Multi-Objective Interpolation Training for Robustness To Label Noise(CVPR2021):MOIT
[[Paper]](https://openaccess.thecvf.com/content/CVPR2021/papers/Ortego_Multi-Objective_Interpolation_Training_for_Robustness_To_Label_Noise_CVPR_2021_paper.pdf)
[[bibtex]](https://openaccess.thecvf.com/content/CVPR2021/html/Ortego_Multi-Objective_Interpolation_Training_for_Robustness_To_Label_Noise_CVPR_2021_paper.html)
<details><summary>summary</summary><div>
特徴量空間でMixUpしている?．今後の研究でしたいことと似ているため読む必要がある．
対照学習を用いたノイジーラベルに対する手法の例として挙げられていた．
</div></details> 
- Keywords : `Contrastive Learning` 'MixUp'


### Dividemix: Learning with noisy labels as semi-supervised learning(2020):DivideMix
[[Paper]](https://arxiv.org/pdf/2002.07394)
[[bibtex]](https://arxiv.org/abs/2002.07394)
<details><summary>summary</summary><div>
co-
</div></details> 
- Keywords : `` 'MixUp'

## TCL内の比較してる手法

### mixup: Beyond empirical risk minimization(2017):MixUp
[[Paper]](https://arxiv.org/pdf/1710.09412)
[[bibtex]](https://arxiv.org/abs/1710.09412)
<details><summary>summary</summary><div>

</div></details> 
- Keywords : `` 'MixUp'

### Probabilistic End-To-End Noise Correction for Learning With Noisy Labels(CVPR2019)
[[Paper]](https://openaccess.thecvf.com/content_CVPR_2019/papers/Yi_Probabilistic_End-To-End_Noise_Correction_for_Learning_With_Noisy_Labels_CVPR_2019_paper.pdf)
[[bibtex]](https://openaccess.thecvf.com/content_CVPR_2019/html/Yi_Probabilistic_End-To-End_Noise_Correction_for_Learning_With_Noisy_Labels_CVPR_2019_paper.html)
<details><summary>summary</summary><div>
  
</div></details> 

### Unsupervised Label Noise Modeling and Loss Correction(PMLR2019)
[[Paper]](http://proceedings.mlr.press/v97/arazo19a/arazo19a.pdf)
[[bibtex]](https://proceedings.mlr.press/v97/arazo19a.html)
<details><summary>summary</summary><div>

</div></details> 

### Early-learning regularization prevents memorization of noisy labels(NIPS2020):ELR
[[Paper]](http://proceedings.mlr.press/v97/arazo19a/arazo19a.pdf)
[[bibtex]](https://proceedings.mlr.press/v97/arazo19a.html)
<details><summary>summary</summary><div>

</div></details> 

### Selective-Supervised Contrastive Learning With Noisy Labels(CVPR2022):Sel-CL
[[Paper]](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Selective-Supervised_Contrastive_Learning_With_Noisy_Labels_CVPR_2022_paper.pdf)
[[code]](https://github.com/ShikunLi/Sel-CL)
[[bibtex]](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Selective-Supervised_Contrastive_Learning_With_Noisy_Labels_CVPR_2022_paper.html)
<details><summary>summary</summary><div>

</div></details> 
- Keywords : `Contrastive Learning` '提案手法を組み込む候補' 


## RankMatch内の比較してる手法
### On Learning Contrastive Representations for Learning With Noisy Labels(CVPR2022):CTRR
[[Paper]](https://openaccess.thecvf.com/content/CVPR2022/papers/Yi_On_Learning_Contrastive_Representations_for_Learning_With_Noisy_Labels_CVPR_2022_paper.pdf)
[[bibtex]](https://openaccess.thecvf.com/content/CVPR2022/html/Yi_On_Learning_Contrastive_Representations_for_Learning_With_Noisy_Labels_CVPR_2022_paper.html)
<details><summary>summary</summary><div>

</div></details> 
- Keywords : `Contrastive Learning`

### Probabilistic End-To-End Noise Correction for Learning With Noisy Labels(CVPR2019)
[[Paper]](https://openaccess.thecvf.com/content_CVPR_2019/papers/Yi_Probabilistic_End-To-End_Noise_Correction_for_Learning_With_Noisy_Labels_CVPR_2019_paper.pdf)
[[bibtex]](https://openaccess.thecvf.com/content_CVPR_2019/html/Yi_Probabilistic_End-To-End_Noise_Correction_for_Learning_With_Noisy_Labels_CVPR_2019_paper.htmll)
<details><summary>summary</summary><div>
ノイズの多いラベルを修正するために、別の一連の研究では、ノイズの多いラベルをネットワーク予測で置き換える自己学習アーキテクチャを提案している
</div></details>
- Keywords : `Contrastive Learning`

### Peer Loss Functions: Learning from Noisy Labels without Knowing Noise Rates(PMLR2020)
[[Paper]](http://proceedings.mlr.press/v119/liu20e/liu20e.pdf)
[[bibtex]](https://proceedings.mlr.press/v119/liu20e.html)
<details><summary>summary</summary><div>
いったんパス
punishment regularization(罰正規化)
</div></details> 

### Robust Training under Label Noise by Over-parameterization(PMLR2022)
[[Paper]](https://proceedings.mlr.press/v162/liu22w/liu22w.pdf)
[[bibtex]](https://proceedings.mlr.press/v162/liu22w.html)
<details><summary>summary</summary><div>
over parameterized term(過剰パラメータ化項)
</div></details> 

### A Closer Look at Memorization in Deep Networks(PMLR2017)
[[Paper]](http://proceedings.mlr.press/v70/arpit17a/arpit17a.pdf)
[[bibtex]](https://proceedings.mlr.press/v70/arpit17a.html)
<details><summary>summary</summary><div>
Memorization Efectについか書かれている論文
</div></details> 
- Keywords : `Memorization Efect`

### Augmentation Strategies for Learning With Noisy Labels(CVPR2021)
[[Paper]](https://openaccess.thecvf.com/content/CVPR2021/papers/Nishi_Augmentation_Strategies_for_Learning_With_Noisy_Labels_CVPR_2021_paper.pdf)
[[bibtex]](https://openaccess.thecvf.com/content/CVPR2021/html/Nishi_Augmentation_Strategies_for_Learning_With_Noisy_Labels_CVPR_2021_paper.html)
<details><summary>summary</summary><div>
損失からGMMを用いてラベルがクリーンである確率を計算している手法．
論文で引くときはDivideMixも一緒にの場所に引用する予定．
</div></details> 

### Understanding deep learning (still) requires rethinking generalization(2021)
[[Paper]](https://dl.acm.org/doi/pdf/10.1145/3446776)
[[bibtex]](https://dl.acm.org/doi/abs/10.1145/3446776)
<details><summary>summary</summary><div>
ノイズへの適合について述べている．
</div></details> 

### Dimensionality reduction by learning an invariant mapping(2006)
[[Paper]](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=1640964)
[[bibtex]](https://ieeexplore.ieee.org/abstract/document/1640964)
<details><summary>summary</summary><div>
引用まだcontrastive learningの始めのところ
SimSiamである
</div></details> 


###  Making Deep Neural Networks Robust to Label Noise: A Loss Correction Approach(2017)
[[Paper]](https://openaccess.thecvf.com/content_cvpr_2017/papers/Patrini_Making_Deep_Neural_CVPR_2017_paper.pdf)
[[bibtex]](https://openaccess.thecvf.com/content_cvpr_2017/html/Patrini_Making_Deep_Neural_CVPR_2017_paper.html)
<details><summary>summary</summary><div>
ノイズ遷移行列使う方法
TCL内で引用されていた
Asymmetricの説明
</div></details> 

### Learning From Noisy Labels By Regularized Estimation Of Annotator Confusion(2019)
[[Paper]](https://openaccess.thecvf.com/content_CVPR_2019/papers/Tanno_Learning_From_Noisy_Labels_by_Regularized_Estimation_of_Annotator_Confusion_CVPR_2019_paper.pdf)
[[bibtex]](https://openaccess.thecvf.com/content_CVPR_2019/html/Tanno_Learning_From_Noisy_Labels_by_Regularized_Estimation_of_Annotator_Confusion_CVPR_2019_paper.html)
<details><summary>summary</summary><div>
ノイズ遷移行列使う方法
TCL内で引用されていた
</div></details> 

### Are Anchor Points Really Indispensable in Label-Noise Learning?(2019)
[[Paper]](https://proceedings.neurips.cc/paper_files/paper/2019/file/9308b0d6e5898366a4a986bc33f3d3e7-Paper.pdf)
[[bibtex]](https://proceedings.neurips.cc/paper/2019/hash/9308b0d6e5898366a4a986bc33f3d3e7-Abstract.html)
<details><summary>summary</summary><div>
ノイズ遷移行列使う方法
TCL内で引用されていた
</div></details> 

### The Multidimensional Wisdom of Crowds(NIPS2010)
[[Paper]](https://proceedings.neurips.cc/paper_files/paper/2010/file/0f9cafd014db7a619ddb4276af0d692c-Paper.pdf)
[[bibtex]](https://proceedings.neurips.cc/paper_files/paper/2010/hash/0f9cafd014db7a619ddb4276af0d692c-Abstract.html)
<details><summary>summary</summary><div>
クラウドソーシングシステムについて述べている．
</div></details> 

## NEIL: Extracting Visual Knowledge from Web Data(ICCV2013)
[[Paper]](https://openaccess.thecvf.com/content_iccv_2013/papers/Chen_NEIL_Extracting_Visual_2013_ICCV_paper.pdf)
[[bibtex]](https://openaccess.thecvf.com/content_iccv_2013/html/Chen_NEIL_Extracting_Visual_2013_ICCV_paper.html)
<details><summary>summary</summary><div>
web使ってデータを集めることが書いてる
</div></details> 

## Harvesting image databases from the web(IEEE2010)
[[bibtex]](https://ieeexplore.ieee.org/abstract/document/5518767)
<details><summary>summary</summary><div>
web使ってデータを集めることが書いてる
</div></details> 

## Visual Recognition by Learning From Web Data: A Weakly Supervised Domain Generalization Approach(CVPR2015)
[[Paper]](https://openaccess.thecvf.com/content_cvpr_2015/papers/Niu_Visual_Recognition_by_2015_CVPR_paper.pdf)
[[bibtex]](https://openaccess.thecvf.com/content_cvpr_2015/html/Niu_Visual_Recognition_by_2015_CVPR_paper.html)
<details><summary>summary</summary><div>
web使ってデータを集めることが書いてる
</div></details> 

## Learning From Massive Noisy Labeled Data for Image Classification(CVPR2015)
[[Paper]](https://openaccess.thecvf.com/content_cvpr_2015/papers/Xiao_Learning_From_Massive_2015_CVPR_paper.pdf)
[[bibtex]](https://openaccess.thecvf.com/content_cvpr_2015/html/Xiao_Learning_From_Massive_2015_CVPR_paper.html)
<details><summary>summary</summary><div>
ノイズ率が8~35%程度のことのところで引用
</div></details> 

## {SELFIE}: Refurbishing Unclean Samples for Robust Deep Learning(PMLR2019)
[[Paper]](http://proceedings.mlr.press/v97/song19b/song19b.pdf)
[[bibtex]](https://proceedings.mlr.press/v97/song19b.html)
<details><summary>summary</summary><div>
ノイズ率が8~35%程度のことのところで引用
</div></details> 

## WebVision Database: Visual Learning and Understanding from Web Data(CoRR2017)
[[Paper]](https://arxiv.org/pdf/1708.02862)
[[bibtex]](https://arxiv.org/abs/1708.02862)
<details><summary>summary</summary><div>
ノイズ率が8~35%程度のことのところで引用
</div></details> 

## Learning with Symmetric Label Noise: The Importance of Being Unhinged(NeurIPS2015)
[[Paper]](https://proceedings.neurips.cc/paper_files/paper/2015/file/45c48cce2e2d7fbdea1afc51c7c6ad26-Paper.pdf)
[[bibtex]](https://proceedings.neurips.cc/paper/2015/hash/45c48cce2e2d7fbdea1afc51c7c6ad26-Abstract.html)
<details><summary>summary</summary><div>
Symmetric
</div></details> 

## Learning multiple layers of features from tiny images(2009cifar)
[[Paper]](http://www.cs.utoronto.ca/~kriz/learning-features-2009-TR.pdf)
<details><summary>summary</summary><div>
Cifar10, Cifar100
</div></details> 

## Imagenet: A large-scale hierarchical image database(2009ImageNer)
[[bibtex]](https://ieeexplore.ieee.org/abstract/document/5206848)
<details><summary>summary</summary><div>
ImageNet
</div></details> 

## Visualizing data using t-SNE(2008t-SNE)
[[pdf]](https://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf?fbcl)
<details><summary>summary</summary><div>
t-SNE
</div></details> 


## データセット系
